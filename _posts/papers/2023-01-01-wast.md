---
layout: paper
categories: papers
permalink: papers/wast
id: wast
title: "Wavelet-Driven Spatiotemporal Predictive Learning: Bridging Frequency and Time Variations"
feature-title: WaST
authors: 
  - Xuesong Nie
  - Yunfeng Yan
  - Siyuan Li
  - Cheng Tan
  - Xi Chen
  - Haoyuan Jin
  - Zhihang Zhu
  - Stan Li
  - Donglian Qi
venue: AAAI Conference on Artificial Intelligence
venue-shorthand: AAAI
location: Vancouver, Canada
year: 2024
url: /papers/wast
pdf: https://arxiv.org/abs/2310.04621
code: https://github.com/xuesongnie
type: conference
figure: /images/papers/wast.png
doi: 10.1145/3491102.3501823
selected: true
feature-description: ScopeViT empowers Transformers with scale-aware capabilities to learn visual information <br><br> <b>Xuesong Nie</b>
image: /images/featured/wast.png
featured: true
feature-order: 1
coming-soon: false
bibtex: |-

    @inproceedings{nie2024wast,
        title={Wavelet-Driven Spatiotemporal Predictive Learning: Bridging Frequency and Time Variations},
        author={Xuesong Nie and Yunfeng Yan and Siyuan Li and Cheng Tan and Xi Chen and Haoyuan Jin and Zhihang Zhu and Stan Z. Li and Donglian Qi},
        booktitle={Annual AAAI Conference on Artificial Intelligence (AAAI)},
        year={2024}
    }
---

Spatiotemporal predictive learning is a paradigm that empowers models to learn spatial and temporal patterns by predicting future frames from past frames in an unsupervised manner. 
This method typically uses recurrent units to capture long-term dependencies, but these units often come with high computational costs and limited performance in real-world scenes. 
This paper presents an innovative Wavelet-based SpatioTemporal (WaST) framework, which extracts and adaptively controls both low and high-frequency components at image and feature levels via 3D discrete wavelet transform for faster processing while maintaining high-quality predictions. 
We propose a Time-Frequency Aware Translator uniquely crafted to efficiently learn short- and long-range spatiotemporal information by individually modeling spatial frequency and temporal variations. 
Meanwhile, we design a wavelet-domain High-Frequency Focal Loss that effectively supervises high-frequency variations. 
Extensive experiments across various real-world scenarios, such as driving scene prediction, traffic flow prediction, human motion capture, and weather forecasting, demonstrate that our proposed WaST achieves state-of-the-art performance over various spatiotemporal prediction methods.